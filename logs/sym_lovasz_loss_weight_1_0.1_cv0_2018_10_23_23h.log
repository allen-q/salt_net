23/10/2018 12:25:56 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - np.sum(X_train_ids): 6319371
23/10/2018 12:25:57 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - np.sum(X_val_ids): 1678629
23/10/2018 12:26:03 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - sym_lovasz_loss_weight_1_0.1_cv0, based on salt_model_v37.4_high_lovasz_loss. use symetric lavasz loss. Set lavasz loss and bce weight to 1:0.1
23/10/2018 12:26:26 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:26:26 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:26:26 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:26:26 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.9
    }

23/10/2018 12:26:26 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (0.1, 1), optimizer, scheduler, train_params, all_data)

23/10/2018 12:26:33 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - ../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp
23/10/2018 12:26:33 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Start Training...
23/10/2018 12:26:33 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f750741b780>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f750741b550>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (0.1, 1), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f75062b2438>, {'model_save_name': '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_weight_1_0.1_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.9})
23/10/2018 12:26:33 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Epoch 1/150
23/10/2018 12:26:33 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - --------------------
23/10/2018 12:30:04 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Train IOU: 0.5258, Acc: 0.8361, Loss: [0.0629, 0.6944, 0.7573] at epoch 1
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - ['../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-10-Of-10']
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Best Val Mean IOU so far: 0.620125
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Val   IOU: 0.6201, Acc: 0.9060, Best Val IOU: 0.6201 at epoch 1
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - LR: [9.94e-05, 0.000994]
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Epoch 2/150
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - --------------------
23/10/2018 12:30:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Pushing logs to git.
23/10/2018 12:34:03 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Train IOU: 0.6126, Acc: 0.8848, Loss: [0.0522, 0.5323, 0.5846] at epoch 2
23/10/2018 12:34:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - ['../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-10-Of-10']
23/10/2018 12:34:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Best Val Mean IOU so far: 0.6503749999999999
23/10/2018 12:34:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Val   IOU: 0.6504, Acc: 0.9150, Best Val IOU: 0.6504 at epoch 2
23/10/2018 12:34:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - LR: [9.88e-05, 0.000988]
23/10/2018 12:34:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Epoch 3/150
23/10/2018 12:34:21 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - --------------------
23/10/2018 12:37:52 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Train IOU: 0.6482, Acc: 0.9011, Loss: [0.0491, 0.4779, 0.527] at epoch 3
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - ['../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_weight_1_0.1_cv0_2018_10_23_23_25_50.ckp-chunk-10-Of-10']
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Best Val Mean IOU so far: 0.6826249999999999
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Val   IOU: 0.6826, Acc: 0.9218, Best Val IOU: 0.6826 at epoch 3
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - LR: [9.82e-05, 0.000982]
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Epoch 4/150
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - --------------------
23/10/2018 12:38:10 - sym_lovasz_loss_weight_1_0.1_cv0 - INFO - Pushing logs to git.
