23/10/2018 12:04:26 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:04:46 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:05:33 - sym_lovasz_loss_cv0 - INFO - np.sum(X_train_ids): 6319371
23/10/2018 12:05:33 - sym_lovasz_loss_cv0 - INFO - np.sum(X_val_ids): 1678629
23/10/2018 12:05:36 - sym_lovasz_loss_cv0 - INFO - sym_lovasz_loss_cv0, based on salt_model_v37.4_high_lovasz_loss. 5 folds CV.
23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.81
    }

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.81
    }

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - ../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - Start Training...
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7158eea080>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7158eea4e0>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.3), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f715822ec50>, {'model_save_name': '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.81})
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - Epoch 1/150
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:17:24 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:17:24 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:17:24 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.81
    }

23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - ../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - Start Training...
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7158263be0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7158263ef0>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.3), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f715599f8d0>, {'model_save_name': '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.81})
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - Epoch 1/150
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:20:57 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.5250, Acc: 0.8323, Loss: [0.5901, 0.2314, 0.8215] at epoch 1
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.622375
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6224, Acc: 0.9130, Best Val IOU: 0.6224 at epoch 1
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - LR: [9.94e-05, 0.000994]
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Epoch 2/150
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.9
    }

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - ../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - Start Training...
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f71545b5240>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f71545b5080>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.3), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f715443a4a8>, {'model_save_name': '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.9})
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - Epoch 1/150
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:28:43 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.5292, Acc: 0.8386, Loss: [0.5822, 0.2281, 0.8103] at epoch 1
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.6141249999999999
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6141, Acc: 0.8998, Best Val IOU: 0.6141 at epoch 1
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - LR: [9.94e-05, 0.000994]
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Epoch 2/150
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:32:50 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6161, Acc: 0.8898, Loss: [0.4297, 0.183, 0.6128] at epoch 2
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.6275
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6275, Acc: 0.9092, Best Val IOU: 0.6275 at epoch 2
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - LR: [9.88e-05, 0.000988]
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - Epoch 3/150
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:36:41 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6383, Acc: 0.8986, Loss: [0.3924, 0.1716, 0.564] at epoch 3
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.647
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6470, Acc: 0.9213, Best Val IOU: 0.6470 at epoch 3
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - LR: [9.82e-05, 0.000982]
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Epoch 4/150
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:40:45 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6469, Acc: 0.9019, Loss: [0.3727, 0.1642, 0.5369] at epoch 4
23/10/2018 12:41:04 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:41:04 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.709375
23/10/2018 12:41:04 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7094, Acc: 0.9336, Best Val IOU: 0.7094 at epoch 4
23/10/2018 12:41:04 - sym_lovasz_loss_cv0 - INFO - LR: [9.76e-05, 0.000976]
23/10/2018 12:41:04 - sym_lovasz_loss_cv0 - INFO - Epoch 5/150
23/10/2018 12:41:04 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:44:36 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6796, Acc: 0.9127, Loss: [0.3437, 0.151, 0.4947] at epoch 5
23/10/2018 12:44:52 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7051, Acc: 0.9341, Best Val IOU: 0.7094 at epoch 5
23/10/2018 12:44:52 - sym_lovasz_loss_cv0 - INFO - LR: [9.7e-05, 0.0009699]
23/10/2018 12:44:52 - sym_lovasz_loss_cv0 - INFO - Epoch 6/150
23/10/2018 12:44:52 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:44:52 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:48:43 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6891, Acc: 0.9170, Loss: [0.3201, 0.1477, 0.4678] at epoch 6
23/10/2018 12:49:01 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:49:01 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.713875
23/10/2018 12:49:01 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7139, Acc: 0.9354, Best Val IOU: 0.7139 at epoch 6
23/10/2018 12:49:01 - sym_lovasz_loss_cv0 - INFO - LR: [9.64e-05, 0.0009639]
23/10/2018 12:49:01 - sym_lovasz_loss_cv0 - INFO - Epoch 7/150
23/10/2018 12:49:01 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:52:34 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6943, Acc: 0.9189, Loss: [0.3088, 0.145, 0.4538] at epoch 7
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.718625
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7186, Acc: 0.9406, Best Val IOU: 0.7186 at epoch 7
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - LR: [9.58e-05, 0.0009579]
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - Epoch 8/150
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:52:52 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:56:41 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7028, Acc: 0.9181, Loss: [0.3195, 0.142, 0.4614] at epoch 8
23/10/2018 12:57:00 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:57:00 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.7265
23/10/2018 12:57:00 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7265, Acc: 0.9391, Best Val IOU: 0.7265 at epoch 8
23/10/2018 12:57:00 - sym_lovasz_loss_cv0 - INFO - LR: [9.52e-05, 0.0009519]
23/10/2018 12:57:00 - sym_lovasz_loss_cv0 - INFO - Epoch 9/150
23/10/2018 12:57:00 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:00:32 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7049, Acc: 0.9230, Loss: [0.295, 0.1387, 0.4338] at epoch 9
23/10/2018 13:00:47 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7041, Acc: 0.9362, Best Val IOU: 0.7265 at epoch 9
23/10/2018 13:00:47 - sym_lovasz_loss_cv0 - INFO - LR: [9.46e-05, 0.0009458]
23/10/2018 13:00:47 - sym_lovasz_loss_cv0 - INFO - Epoch 10/150
23/10/2018 13:00:47 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:00:47 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 13:04:34 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7042, Acc: 0.9183, Loss: [0.3046, 0.1374, 0.442] at epoch 10
23/10/2018 13:04:52 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 13:04:52 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.741
23/10/2018 13:04:52 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7410, Acc: 0.9439, Best Val IOU: 0.7410 at epoch 10
23/10/2018 13:04:52 - sym_lovasz_loss_cv0 - INFO - LR: [9.4e-05, 0.0009398]
23/10/2018 13:04:52 - sym_lovasz_loss_cv0 - INFO - Epoch 11/150
23/10/2018 13:04:52 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:08:25 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7140, Acc: 0.9228, Loss: [0.2928, 0.1332, 0.426] at epoch 11
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.744375
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7444, Acc: 0.9468, Best Val IOU: 0.7444 at epoch 11
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - LR: [9.34e-05, 0.0009338]
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - Epoch 12/150
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:08:43 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 13:12:29 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7207, Acc: 0.9251, Loss: [0.2712, 0.1264, 0.3976] at epoch 12
23/10/2018 13:12:48 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 13:12:48 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.751875
23/10/2018 13:12:48 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7519, Acc: 0.9492, Best Val IOU: 0.7519 at epoch 12
23/10/2018 13:12:48 - sym_lovasz_loss_cv0 - INFO - LR: [9.28e-05, 0.0009277]
23/10/2018 13:12:48 - sym_lovasz_loss_cv0 - INFO - Epoch 13/150
23/10/2018 13:12:48 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:16:19 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7187, Acc: 0.9248, Loss: [0.2682, 0.1274, 0.3957] at epoch 13
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.7647499999999999
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7647, Acc: 0.9520, Best Val IOU: 0.7647 at epoch 13
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - LR: [9.22e-05, 0.0009217]
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - Epoch 14/150
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:16:37 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 13:20:25 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7230, Acc: 0.9281, Loss: [0.2873, 0.1312, 0.4186] at epoch 14
23/10/2018 13:20:40 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7500, Acc: 0.9449, Best Val IOU: 0.7647 at epoch 14
23/10/2018 13:20:40 - sym_lovasz_loss_cv0 - INFO - LR: [9.16e-05, 0.0009156]
23/10/2018 13:20:40 - sym_lovasz_loss_cv0 - INFO - Epoch 15/150
23/10/2018 13:20:40 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:24:11 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7369, Acc: 0.9312, Loss: [0.2765, 0.1248, 0.4013] at epoch 15
23/10/2018 13:24:26 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7592, Acc: 0.9453, Best Val IOU: 0.7647 at epoch 15
23/10/2018 13:24:26 - sym_lovasz_loss_cv0 - INFO - LR: [9.1e-05, 0.0009095]
23/10/2018 13:24:26 - sym_lovasz_loss_cv0 - INFO - Epoch 16/150
23/10/2018 13:24:26 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:24:26 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 13:28:12 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7494, Acc: 0.9341, Loss: [0.2516, 0.1155, 0.3671] at epoch 16
23/10/2018 13:28:27 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7570, Acc: 0.9483, Best Val IOU: 0.7647 at epoch 16
23/10/2018 13:28:27 - sym_lovasz_loss_cv0 - INFO - LR: [9.03e-05, 0.0009035]
23/10/2018 13:28:27 - sym_lovasz_loss_cv0 - INFO - Epoch 17/150
23/10/2018 13:28:27 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:31:58 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7464, Acc: 0.9361, Loss: [0.2491, 0.1168, 0.3659] at epoch 17
23/10/2018 13:32:13 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7601, Acc: 0.9483, Best Val IOU: 0.7647 at epoch 17
23/10/2018 13:32:13 - sym_lovasz_loss_cv0 - INFO - LR: [8.97e-05, 0.0008974]
23/10/2018 13:32:13 - sym_lovasz_loss_cv0 - INFO - Epoch 18/150
23/10/2018 13:32:13 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:32:13 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 13:36:00 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7506, Acc: 0.9351, Loss: [0.2427, 0.1166, 0.3593] at epoch 18
23/10/2018 13:36:18 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 13:36:18 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.7723750000000001
23/10/2018 13:36:18 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7724, Acc: 0.9508, Best Val IOU: 0.7724 at epoch 18
23/10/2018 13:36:18 - sym_lovasz_loss_cv0 - INFO - LR: [8.91e-05, 0.0008913]
23/10/2018 13:36:18 - sym_lovasz_loss_cv0 - INFO - Epoch 19/150
23/10/2018 13:36:18 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:39:49 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7528, Acc: 0.9376, Loss: [0.2555, 0.115, 0.3705] at epoch 19
23/10/2018 13:40:04 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7575, Acc: 0.9477, Best Val IOU: 0.7724 at epoch 19
23/10/2018 13:40:04 - sym_lovasz_loss_cv0 - INFO - LR: [8.85e-05, 0.0008852]
23/10/2018 13:40:04 - sym_lovasz_loss_cv0 - INFO - Epoch 20/150
23/10/2018 13:40:04 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:40:04 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 13:43:52 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7511, Acc: 0.9390, Loss: [0.2394, 0.1132, 0.3526] at epoch 20
23/10/2018 13:44:07 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7620, Acc: 0.9489, Best Val IOU: 0.7724 at epoch 20
23/10/2018 13:44:07 - sym_lovasz_loss_cv0 - INFO - Skip pushing model to git as there's no improvement
23/10/2018 13:44:07 - sym_lovasz_loss_cv0 - INFO - LR: [8.79e-05, 0.0008792]
23/10/2018 13:44:07 - sym_lovasz_loss_cv0 - INFO - Epoch 21/150
23/10/2018 13:44:07 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:47:38 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.7533, Acc: 0.9404, Loss: [0.2405, 0.1131, 0.3536] at epoch 21
23/10/2018 13:47:53 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.7700, Acc: 0.9514, Best Val IOU: 0.7724 at epoch 21
23/10/2018 13:47:53 - sym_lovasz_loss_cv0 - INFO - LR: [8.73e-05, 0.0008731]
23/10/2018 13:47:53 - sym_lovasz_loss_cv0 - INFO - Epoch 22/150
23/10/2018 13:47:53 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 13:47:53 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
