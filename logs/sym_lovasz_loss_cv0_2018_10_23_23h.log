23/10/2018 12:04:26 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:04:46 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:05:33 - sym_lovasz_loss_cv0 - INFO - np.sum(X_train_ids): 6319371
23/10/2018 12:05:33 - sym_lovasz_loss_cv0 - INFO - np.sum(X_val_ids): 1678629
23/10/2018 12:05:36 - sym_lovasz_loss_cv0 - INFO - sym_lovasz_loss_cv0, based on salt_model_v37.4_high_lovasz_loss. 5 folds CV.
23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.81
    }

23/10/2018 12:11:34 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.81
    }

23/10/2018 12:15:42 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - ../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - Start Training...
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7158eea080>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7158eea4e0>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.3), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f715822ec50>, {'model_save_name': '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.81})
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - Epoch 1/150
23/10/2018 12:15:43 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:17:24 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:17:24 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:17:24 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.81
    }

23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - ../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - Start Training...
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7158263be0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7158263ef0>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.3), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f715599f8d0>, {'model_save_name': '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.81})
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - Epoch 1/150
23/10/2018 12:17:25 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:20:57 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.5250, Acc: 0.8323, Loss: [0.5901, 0.2314, 0.8215] at epoch 1
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.622375
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6224, Acc: 0.9130, Best Val IOU: 0.6224 at epoch 1
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - LR: [9.94e-05, 0.000994]
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Epoch 2/150
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:21:15 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
p = Pipeline_Salt()
p.flip_left_right(probability=0.5)
p.rotate90(0.25)
p.rotate270(0.25)
p.random_brightness(probability=0.5, min_factor=0.8, max_factor=1.2)
p.random_contrast(probability=0.5, min_factor=0.8, max_factor=1.2)
p.rotate_random_align(probability=0.5)
p.crop_random_align(probability=0.5, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
train_data_params = {'batch_size': 32,
                     #'sampler': weighted_sampler,
                     'shuffle': True,
                     'drop_last': False}

val_data_params = {'batch_size': 32,
                   'shuffle': True,
                   'drop_last': False}

train_dataLoader = (
    DataLoader(SaltDataset(X_train, y_train, depth_train,
                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,
                           transform=p.torch_transform()), **train_data_params)
)

val_dataLoader = (
    DataLoader(SaltDataset(X_val, y_val, depth_val, 
                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)
)

dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
saltnet = UResNet(pretrained=True)
loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))
#loss_focal = FocalLoss(0.25, 2, logits=True)
loss_lovasz_hinge = LovaszHingeLoss(symetric=True)
resnet_params = (
    list(saltnet.conv1.parameters()) + 
    list(saltnet.encoder2.parameters()) + 
    list(saltnet.encoder3.parameters()) + 
    list(saltnet.encoder4.parameters()) + 
    list(saltnet.encoder5.parameters())
)

unet_params = (
    list(saltnet.center.parameters()) + 
    list(saltnet.decoder5.parameters()) + 
    list(saltnet.decoder4.parameters()) + 
    list(saltnet.decoder3.parameters()) + 
    list(saltnet.decoder2.parameters()) + 
    list(saltnet.decoder1.parameters())  + 
    list(saltnet.se_f.parameters()) + 
    list(saltnet.outc.parameters())
)
optimizer = optim.Adam([    
    {'params': resnet_params, 'lr': 1e-4},
    {'params': unet_params, 'lr': 1e-3},
], weight_decay=0.0001)


scheduler = PolyLR(optimizer, [1e-4, 1e-3], lr_decay_iter=1, max_iter=150, power=0.9)
model_save_name = model_file_suffix
log.info(model_save_name)

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
train_params = {
    'model_save_name': model_save_name,
    'save_model_every': 20,
    'save_log_every': 2,
    'num_epochs': 150,
    'log': log,
    'mask_cutoff': 0.,
    'model_save_iou_threshold': 0.9
    }

23/10/2018 12:25:10 - sym_lovasz_loss_cv0 - INFO - 
train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.3), optimizer, scheduler, train_params, all_data)

23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - ../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - Start Training...
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f71545b5240>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f71545b5080>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.3), Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
), <salt_func_lib.PolyLR object at 0x7f715443a4a8>, {'model_save_name': '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 150, 'log': <Logger sym_lovasz_loss_cv0 (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.9})
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - Epoch 1/150
23/10/2018 12:25:11 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:28:43 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.5292, Acc: 0.8386, Loss: [0.5822, 0.2281, 0.8103] at epoch 1
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.6141249999999999
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6141, Acc: 0.8998, Best Val IOU: 0.6141 at epoch 1
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - LR: [9.94e-05, 0.000994]
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Epoch 2/150
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:29:01 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
23/10/2018 12:32:50 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6161, Acc: 0.8898, Loss: [0.4297, 0.183, 0.6128] at epoch 2
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.6275
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6275, Acc: 0.9092, Best Val IOU: 0.6275 at epoch 2
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - LR: [9.88e-05, 0.000988]
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - Epoch 3/150
23/10/2018 12:33:08 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:36:41 - sym_lovasz_loss_cv0 - INFO - Train IOU: 0.6383, Acc: 0.8986, Loss: [0.3924, 0.1716, 0.564] at epoch 3
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - ['../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-1-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-2-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-3-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-4-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-5-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-6-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-7-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-8-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-9-Of-10', '../salt_net/sym_lovasz_loss_cv0_2018_10_23_23_03_42.ckp-chunk-10-Of-10']
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Best Val Mean IOU so far: 0.647
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Val   IOU: 0.6470, Acc: 0.9213, Best Val IOU: 0.6470 at epoch 3
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - LR: [9.82e-05, 0.000982]
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Epoch 4/150
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - --------------------
23/10/2018 12:36:59 - sym_lovasz_loss_cv0 - INFO - Pushing logs to git.
